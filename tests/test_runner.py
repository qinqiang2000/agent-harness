"""
å‘ç¥¨äº‘å®¢æœ Skill æµ‹è¯•æ‰§è¡Œå™¨

æ‰§è¡Œ test_questions.py ä¸­å®šä¹‰çš„æµ‹è¯•ç”¨ä¾‹ï¼Œç”Ÿæˆæµ‹è¯•æŠ¥å‘Š

ç”¨æ³•:
    python tests/test_runner.py                    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    python tests/test_runner.py --category äº§å“è¯†åˆ«  # æŒ‰ç±»åˆ«è¿è¡Œ
    python tests/test_runner.py --id PROD-001      # è¿è¡Œå•ä¸ªæµ‹è¯•
    python tests/test_runner.py --list             # åˆ—å‡ºæ‰€æœ‰æµ‹è¯•
    python tests/test_runner.py --quick            # å¿«é€Ÿæµ‹è¯•ï¼ˆæ¯ç±»åˆ«1ä¸ªï¼‰
"""

import argparse
import asyncio
import json
import sys
from dataclasses import asdict
from datetime import datetime
from pathlib import Path
from typing import Optional

from api.models.requests import QueryRequest
from api.services.agent_service import AgentService
from api.services.session_service import InMemorySessionService

from test_questions import (
    TEST_CASES,
    TestCase,
    TestCategory,
    get_test_cases_by_category,
    get_test_case_by_id,
)


class TestResult:
    """æµ‹è¯•ç»“æœ"""

    def __init__(self, test_case: TestCase):
        self.test_case = test_case
        self.response: str = ""
        self.tool_uses: list[dict] = []
        self.error: Optional[str] = None
        self.passed: bool = False
        self.evaluation: dict = {}
        self.duration_ms: int = 0


class SkillTestRunner:
    """Skill æµ‹è¯•æ‰§è¡Œå™¨"""

    def __init__(self, verbose: bool = True):
        self.session_service = InMemorySessionService()
        self.agent_service = AgentService(self.session_service)
        self.results: list[TestResult] = []
        self.verbose = verbose

    async def run_test(self, test_case: TestCase) -> TestResult:
        """è¿è¡Œå•ä¸ªæµ‹è¯•ç”¨ä¾‹"""
        result = TestResult(test_case)
        start_time = datetime.now()

        if self.verbose:
            print(f"\n{'='*70}")
            print(f"[{test_case.id}] {test_case.name}")
            print(f"{'='*70}")
            print(f"ç±»åˆ«: {test_case.category.value}")
            print(f"è¾“å…¥: {test_case.query}")
            print(f"\né¢„æœŸè¡Œä¸º:")
            for behavior in test_case.expected_behaviors:
                print(f"  - {behavior}")
            print(f"\n{'â”€'*70}")
            print("å®é™…å“åº”:")

        # åˆ›å»ºè¯·æ±‚
        request = QueryRequest(
            tenant_id="test-tenant",
            prompt=test_case.query,
            skill="customer-service",
            language="zh-CN"
        )

        try:
            async for event in self.agent_service.process_query(request):
                if event.get("type") == "assistant_message":
                    content = event.get("content", "")
                    if content:
                        if self.verbose:
                            print(content, end="", flush=True)
                        result.response += content

                elif event.get("type") == "tool_use":
                    tool_info = {
                        "tool": event.get("tool_name"),
                        "input": event.get("tool_input", {})
                    }
                    result.tool_uses.append(tool_info)

            # è®¡ç®—è€—æ—¶
            result.duration_ms = int((datetime.now() - start_time).total_seconds() * 1000)

            if self.verbose:
                print(f"\n{'â”€'*70}")
                if result.tool_uses:
                    print(f"å·¥å…·è°ƒç”¨ ({len(result.tool_uses)}):")
                    for tool in result.tool_uses:
                        print(f"  - {tool['tool']}")
                        if tool['tool'] == 'Grep':
                            print(f"    pattern: {tool['input'].get('pattern', '')}")
                            print(f"    path: {tool['input'].get('path', '')}")
                        elif tool['tool'] == 'Read':
                            print(f"    file: {tool['input'].get('file_path', '')}")
                print(f"\nè€—æ—¶: {result.duration_ms}ms")

            # è‡ªåŠ¨è¯„ä¼°
            result.evaluation = self._evaluate_result(test_case, result)
            result.passed = result.evaluation.get("passed", False)

            if self.verbose:
                self._print_evaluation(result)

        except Exception as e:
            result.error = str(e)
            if self.verbose:
                print(f"\nâŒ æµ‹è¯•å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()

        self.results.append(result)
        return result

    def _evaluate_result(self, test_case: TestCase, result: TestResult) -> dict:
        """è‡ªåŠ¨è¯„ä¼°æµ‹è¯•ç»“æœ"""
        evaluation = {
            "passed": True,
            "checks": [],
            "warnings": []
        }

        response = result.response.lower()

        # æ£€æŸ¥å¿…é¡»åŒ…å«çš„å†…å®¹
        for expected in test_case.expected_output_contains:
            if expected.lower() not in response:
                evaluation["checks"].append({
                    "type": "contains",
                    "expected": expected,
                    "passed": False
                })
                evaluation["passed"] = False
            else:
                evaluation["checks"].append({
                    "type": "contains",
                    "expected": expected,
                    "passed": True
                })

        # æ£€æŸ¥ä¸åº”åŒ…å«çš„å†…å®¹
        for not_expected in test_case.expected_output_not_contains:
            if not_expected.lower() in response:
                evaluation["checks"].append({
                    "type": "not_contains",
                    "not_expected": not_expected,
                    "passed": False
                })
                evaluation["passed"] = False
            else:
                evaluation["checks"].append({
                    "type": "not_contains",
                    "not_expected": not_expected,
                    "passed": True
                })

        # æ£€æŸ¥ç›®å½•æœç´¢
        if test_case.expected_directory:
            dir_searched = False
            for tool in result.tool_uses:
                if tool['tool'] in ['Grep', 'Glob', 'Read']:
                    path = tool['input'].get('path', '') or tool['input'].get('file_path', '')
                    if test_case.expected_directory in path:
                        dir_searched = True
                        break
            if not dir_searched:
                evaluation["warnings"].append(
                    f"æœªæœç´¢é¢„æœŸç›®å½•: {test_case.expected_directory}"
                )

        # æ£€æŸ¥äº§å“è¯†åˆ«ï¼ˆå¦‚æœ‰æ ‡å‡†è¯æœ¯è¦æ±‚ï¼Œæ£€æŸ¥æ˜¯å¦æ­£ç¡®è¿”å›ï¼‰
        if "æ ‡å‡†è¯æœ¯" in str(test_case.expected_behaviors):
            if "æŠ±æ­‰" in response and "çŸ¥è¯†åº“æ²¡æ‰¾åˆ°" in response:
                evaluation["checks"].append({
                    "type": "standard_reply",
                    "passed": True
                })
            else:
                evaluation["warnings"].append("æœªä½¿ç”¨æ ‡å‡†è¯æœ¯")

        # å¦‚æœæ²¡æœ‰ä»»ä½•æ£€æŸ¥é¡¹ï¼Œæ ‡è®°ä¸ºéœ€äººå·¥éªŒè¯
        if not evaluation["checks"]:
            evaluation["manual_review"] = True
            evaluation["passed"] = True  # é»˜è®¤é€šè¿‡ï¼Œä½†éœ€äººå·¥å®¡æ ¸

        return evaluation

    def _print_evaluation(self, result: TestResult):
        """æ‰“å°è¯„ä¼°ç»“æœ"""
        eval = result.evaluation
        status = "âœ… é€šè¿‡" if result.passed else "âŒ å¤±è´¥"
        print(f"\nè¯„ä¼°: {status}")

        if eval.get("checks"):
            print("  æ£€æŸ¥é¡¹:")
            for check in eval["checks"]:
                icon = "âœ“" if check["passed"] else "âœ—"
                if check["type"] == "contains":
                    print(f"    {icon} åŒ…å« '{check['expected']}'")
                elif check["type"] == "not_contains":
                    print(f"    {icon} ä¸åŒ…å« '{check['not_expected']}'")
                elif check["type"] == "standard_reply":
                    print(f"    {icon} ä½¿ç”¨æ ‡å‡†è¯æœ¯")

        if eval.get("warnings"):
            print("  è­¦å‘Š:")
            for warning in eval["warnings"]:
                print(f"    âš  {warning}")

        if eval.get("manual_review"):
            print("  ğŸ“‹ éœ€äººå·¥å®¡æ ¸")

    async def run_all(self, test_cases: Optional[list[TestCase]] = None):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        cases = test_cases or TEST_CASES

        print(f"""
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ å‘ç¥¨äº‘å®¢æœ Skill æµ‹è¯•å¥—ä»¶                                            â”‚
â”‚ å…± {len(cases):2d} ä¸ªæµ‹è¯•ç”¨ä¾‹                                                   â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
        """)

        for i, test_case in enumerate(cases, 1):
            print(f"\n[{i}/{len(cases)}] è¿è¡Œæµ‹è¯•...")
            await self.run_test(test_case)

        self.print_summary()

    def print_summary(self):
        """æ‰“å°æµ‹è¯•æ‘˜è¦"""
        print(f"\n\n{'='*70}")
        print("æµ‹è¯•æ‘˜è¦")
        print(f"{'='*70}")

        total = len(self.results)
        passed = sum(1 for r in self.results if r.passed)
        failed = sum(1 for r in self.results if not r.passed)
        errors = sum(1 for r in self.results if r.error)
        manual_review = sum(1 for r in self.results if r.evaluation.get("manual_review"))

        print(f"æ€»æµ‹è¯•æ•°: {total}")
        print(f"  âœ… é€šè¿‡: {passed}")
        print(f"  âŒ å¤±è´¥: {failed}")
        print(f"  ğŸ’¥ å¼‚å¸¸: {errors}")
        print(f"  ğŸ“‹ éœ€äººå·¥å®¡æ ¸: {manual_review}")

        avg_duration = sum(r.duration_ms for r in self.results) / total if total else 0
        print(f"\nå¹³å‡è€—æ—¶: {avg_duration:.0f}ms")

        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        print(f"\næŒ‰ç±»åˆ«ç»Ÿè®¡:")
        for category in TestCategory:
            cat_results = [r for r in self.results if r.test_case.category == category]
            if cat_results:
                cat_passed = sum(1 for r in cat_results if r.passed)
                print(f"  {category.value}: {cat_passed}/{len(cat_results)}")

        # å¤±è´¥çš„æµ‹è¯•
        failed_results = [r for r in self.results if not r.passed]
        if failed_results:
            print(f"\nå¤±è´¥çš„æµ‹è¯•:")
            for r in failed_results:
                print(f"  âŒ [{r.test_case.id}] {r.test_case.name}")
                if r.error:
                    print(f"     é”™è¯¯: {r.error}")

    def export_report(self, filepath: str):
        """å¯¼å‡ºæµ‹è¯•æŠ¥å‘Š"""
        report = {
            "generated_at": datetime.now().isoformat(),
            "summary": {
                "total": len(self.results),
                "passed": sum(1 for r in self.results if r.passed),
                "failed": sum(1 for r in self.results if not r.passed),
                "errors": sum(1 for r in self.results if r.error),
            },
            "results": []
        }

        for r in self.results:
            report["results"].append({
                "id": r.test_case.id,
                "name": r.test_case.name,
                "category": r.test_case.category.value,
                "query": r.test_case.query,
                "passed": r.passed,
                "response": r.response[:500] + "..." if len(r.response) > 500 else r.response,
                "tool_uses": r.tool_uses,
                "evaluation": r.evaluation,
                "error": r.error,
                "duration_ms": r.duration_ms
            })

        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        print(f"\næŠ¥å‘Šå·²å¯¼å‡º: {filepath}")


def list_tests():
    """åˆ—å‡ºæ‰€æœ‰æµ‹è¯•ç”¨ä¾‹"""
    print(f"\n{'='*70}")
    print("å‘ç¥¨äº‘å®¢æœ Skill æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨")
    print(f"{'='*70}")
    print(f"å…± {len(TEST_CASES)} ä¸ªæµ‹è¯•ç”¨ä¾‹\n")

    for category in TestCategory:
        cases = get_test_cases_by_category(category)
        if cases:
            print(f"\n[{category.value}] ({len(cases)} ä¸ª)")
            for tc in cases:
                print(f"  {tc.id}: {tc.name}")
                print(f"       Q: {tc.query[:50]}{'...' if len(tc.query) > 50 else ''}")


async def main():
    parser = argparse.ArgumentParser(description="å‘ç¥¨äº‘å®¢æœ Skill æµ‹è¯•æ‰§è¡Œå™¨")
    parser.add_argument("--list", action="store_true", help="åˆ—å‡ºæ‰€æœ‰æµ‹è¯•ç”¨ä¾‹")
    parser.add_argument("--id", type=str, help="è¿è¡ŒæŒ‡å®šIDçš„æµ‹è¯•ç”¨ä¾‹")
    parser.add_argument("--category", type=str, help="è¿è¡ŒæŒ‡å®šç±»åˆ«çš„æµ‹è¯•ç”¨ä¾‹")
    parser.add_argument("--quick", action="store_true", help="å¿«é€Ÿæµ‹è¯•ï¼ˆæ¯ç±»åˆ«1ä¸ªï¼‰")
    parser.add_argument("--report", type=str, help="å¯¼å‡ºæŠ¥å‘Šåˆ°æŒ‡å®šæ–‡ä»¶")
    parser.add_argument("--quiet", action="store_true", help="é™é»˜æ¨¡å¼")

    args = parser.parse_args()

    if args.list:
        list_tests()
        return

    runner = SkillTestRunner(verbose=not args.quiet)

    # ç¡®å®šè¦è¿è¡Œçš„æµ‹è¯•ç”¨ä¾‹
    test_cases = None

    if args.id:
        tc = get_test_case_by_id(args.id)
        if tc:
            test_cases = [tc]
        else:
            print(f"é”™è¯¯: æœªæ‰¾åˆ°æµ‹è¯•ç”¨ä¾‹ {args.id}")
            sys.exit(1)

    elif args.category:
        try:
            category = TestCategory(args.category)
            test_cases = get_test_cases_by_category(category)
            if not test_cases:
                print(f"é”™è¯¯: ç±»åˆ« '{args.category}' ä¸­æ²¡æœ‰æµ‹è¯•ç”¨ä¾‹")
                sys.exit(1)
        except ValueError:
            print(f"é”™è¯¯: æ— æ•ˆçš„ç±»åˆ« '{args.category}'")
            print(f"æœ‰æ•ˆç±»åˆ«: {[c.value for c in TestCategory]}")
            sys.exit(1)

    elif args.quick:
        # æ¯ä¸ªç±»åˆ«å–ç¬¬ä¸€ä¸ª
        test_cases = []
        for category in TestCategory:
            cases = get_test_cases_by_category(category)
            if cases:
                test_cases.append(cases[0])

    # è¿è¡Œæµ‹è¯•
    await runner.run_all(test_cases)

    # å¯¼å‡ºæŠ¥å‘Š
    if args.report:
        runner.export_report(args.report)
    else:
        # é»˜è®¤å¯¼å‡ºåˆ° tests/reports/
        report_dir = Path(__file__).parent / "reports"
        report_dir.mkdir(exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = report_dir / f"test_report_{timestamp}.json"
        runner.export_report(str(report_path))


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\næµ‹è¯•è¢«ä¸­æ–­")
        sys.exit(0)
